{"cells":[{"cell_type":"markdown","metadata":{"id":"Isqxp9-he8hy"},"source":["# Campus Waste Intelligence – Model Testing\n","\n","This notebook loads pre‑trained forecasting models for different canteen sections and validates their predictions on recent data. The models (XGBoost, Random Forest, SVM, Prophet, SARIMA, LSTM, and simple baselines) were saved during the training phase and are now tested to ensure they load correctly and produce plausible outputs."]},{"cell_type":"code","source":["!pip install pmdarima"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx8UXgfIfQmw","executionInfo":{"status":"ok","timestamp":1772319752231,"user_tz":360,"elapsed":6003,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"31a22cf7-85b9-47ff-8c27-723332570191"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pmdarima\n","  Downloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.5 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.3)\n","Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.0.2)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\n","Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (0.14.6)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.5.0)\n","Requirement already satisfied: setuptools!=50.0.0,>=42 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (26.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14.5->pmdarima) (1.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n","Downloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (689 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pmdarima\n","Successfully installed pmdarima-2.1.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"21P4Mv0ze8h3","executionInfo":{"status":"ok","timestamp":1772319760646,"user_tz":360,"elapsed":8408,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["import os\n","import joblib\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from prophet import Prophet\n","import pmdarima as pm\n","\n","# Configuration\n","LOOKBACK = 7\n","LSTM_HIDDEN = 50\n","LSTM_LAYERS = 2"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"sRv9ouLDe8h5","executionInfo":{"status":"ok","timestamp":1772319760663,"user_tz":360,"elapsed":6,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    \"\"\"Simple LSTM for univariate time series forecasting.\"\"\"\n","    def __init__(self, input_size=1, hidden_size=LSTM_HIDDEN,\n","                 num_layers=LSTM_LAYERS, output_size=1):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        # x shape: (batch, seq_len, input_size)\n","        out, _ = self.lstm(x)\n","        # Use output of last time step\n","        out = self.fc(out[:, -1, :])\n","        return out.squeeze()"]},{"cell_type":"markdown","metadata":{"id":"oG2O6Rwce8h6"},"source":["## 1. Mount Google Drive and Set Working Directory\n","\n","All data and model files are stored on Google Drive. We mount the drive and navigate to the project folder."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N7P2A6Ae8h6","executionInfo":{"status":"ok","timestamp":1772319775948,"user_tz":360,"elapsed":15288,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"3f9b6d5a-da83-46e2-ea52-395d3c7d4a2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/UAB/FDS/campus-waste-intelligence\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir(\"/content/drive/MyDrive/UAB/FDS/campus-waste-intelligence\")\n","print(\"Current working directory:\", os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"CeY45cRhe8h7"},"source":["## 2. Load and Prepare Data\n","\n","We read the cleaned food waste records and aggregate them by day and canteen section. The result is a wide time series where each column represents a section."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"VM2MWXLte8h7","executionInfo":{"status":"ok","timestamp":1772319776710,"user_tz":360,"elapsed":761,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"c93f64ed-87b1-427e-c71d-a3d5e14b7215"},"outputs":[{"output_type":"stream","name":"stdout","text":["Daily data shape: (61, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["Canteen_Section      A      B      C      D\n","Date                                       \n","2025-06-11       29.90  26.85  27.72  37.59\n","2025-06-12       32.99  34.36  33.39  31.45\n","2025-06-13       32.99  28.56  30.40  31.51\n","2025-06-14       21.74  26.84  35.79  32.74\n","2025-06-15       30.39  32.22  29.09  32.40"],"text/html":["\n","  <div id=\"df-dc927585-d82b-410e-b693-a15b9d8c0027\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Canteen_Section</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2025-06-11</th>\n","      <td>29.90</td>\n","      <td>26.85</td>\n","      <td>27.72</td>\n","      <td>37.59</td>\n","    </tr>\n","    <tr>\n","      <th>2025-06-12</th>\n","      <td>32.99</td>\n","      <td>34.36</td>\n","      <td>33.39</td>\n","      <td>31.45</td>\n","    </tr>\n","    <tr>\n","      <th>2025-06-13</th>\n","      <td>32.99</td>\n","      <td>28.56</td>\n","      <td>30.40</td>\n","      <td>31.51</td>\n","    </tr>\n","    <tr>\n","      <th>2025-06-14</th>\n","      <td>21.74</td>\n","      <td>26.84</td>\n","      <td>35.79</td>\n","      <td>32.74</td>\n","    </tr>\n","    <tr>\n","      <th>2025-06-15</th>\n","      <td>30.39</td>\n","      <td>32.22</td>\n","      <td>29.09</td>\n","      <td>32.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc927585-d82b-410e-b693-a15b9d8c0027')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dc927585-d82b-410e-b693-a15b9d8c0027 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dc927585-d82b-410e-b693-a15b9d8c0027');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"daily_wide","summary":"{\n  \"name\": \"daily_wide\",\n  \"rows\": 61,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-06-11 00:00:00\",\n        \"max\": \"2025-08-10 00:00:00\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"2025-06-11 00:00:00\",\n          \"2025-06-16 00:00:00\",\n          \"2025-07-27 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.084822401270179,\n        \"min\": 15.75,\n        \"max\": 39.660000000000004,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          29.9,\n          22.84,\n          29.729999999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.137643540334516,\n        \"min\": 16.56,\n        \"max\": 41.32,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          26.85,\n          27.66,\n          31.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.2189198419730385,\n        \"min\": 15.67,\n        \"max\": 39.7,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          27.72,\n          29.83,\n          37.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.090214581024489,\n        \"min\": 13.55,\n        \"max\": 37.59,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          37.59,\n          29.87,\n          25.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["DATA_PATH = 'data/food_waste_cleaned.csv'\n","df = pd.read_csv(DATA_PATH, parse_dates=['Date'])\n","\n","# Aggregate daily waste per section\n","daily_section = (\n","    df.groupby(['Date', 'Canteen_Section'])['Waste_Weight_kg']\n","      .sum()\n","      .reset_index()\n","      .rename(columns={'Waste_Weight_kg': 'Total_Waste_kg'})\n",")\n","\n","# Pivot to wide format (one column per section)\n","daily_wide = (\n","    daily_section\n","    .pivot(index='Date', columns='Canteen_Section', values='Total_Waste_kg')\n","    .fillna(0)\n","    .sort_index()\n","    .asfreq('D')\n","    .fillna(0)\n",")\n","\n","print(\"Daily data shape:\", daily_wide.shape)\n","daily_wide.head()"]},{"cell_type":"markdown","metadata":{"id":"cX5sLtaAe8h7"},"source":["## 3. Feature Engineering Function\n","\n","The models were trained on a set of features including calendar variables, lagged values, and rolling statistics. We recreate exactly the same features for each section so that the test input matches the training format."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SwAyMCome8h8","executionInfo":{"status":"ok","timestamp":1772319776719,"user_tz":360,"elapsed":4,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def create_features_for_series(series):\n","    \"\"\"\n","    Build a DataFrame with features used during training.\n","    The input series is a daily time series (pandas Series with DatetimeIndex).\n","    \"\"\"\n","    df_ml = pd.DataFrame(index=series.index)\n","    df_ml['y'] = series.values\n","    df_ml['dayofweek'] = df_ml.index.dayofweek\n","    df_ml['day']       = df_ml.index.day\n","    df_ml['month']     = df_ml.index.month\n","    df_ml['quarter']   = df_ml.index.quarter\n","    df_ml['weekend']   = (df_ml.index.dayofweek >= 5).astype(int)\n","\n","    # Lags\n","    for lag in [1, 2, 3, 7, 14]:\n","        df_ml[f'lag_{lag}'] = df_ml['y'].shift(lag)\n","\n","    # Rolling statistics (using shifted values to avoid leakage)\n","    shifted = df_ml['y'].shift(1)\n","    df_ml['rolling_mean_7'] = shifted.rolling(7).mean()\n","    df_ml['rolling_std_7']  = shifted.rolling(7).std()\n","    df_ml['rolling_min_7']  = shifted.rolling(7).min()\n","    df_ml['rolling_max_7']  = shifted.rolling(7).max()\n","    df_ml['ewm_mean_7']     = shifted.ewm(span=7).mean()\n","\n","    # Drop rows with NaN (created by shifts and rolling windows)\n","    df_ml.dropna(inplace=True)\n","    return df_ml"]},{"cell_type":"markdown","metadata":{"id":"DLyjg4Gre8h8"},"source":["## 4. Generate Feature DataFrames for All Sections\n","\n","We apply the feature function to each section’s time series and store the results in a dictionary."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pGVW5MD8e8h8","executionInfo":{"status":"ok","timestamp":1772319776741,"user_tz":360,"elapsed":18,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["feature_dfs = {}\n","for sec in daily_wide.columns:\n","    feature_dfs[sec] = create_features_for_series(daily_wide[sec])"]},{"cell_type":"markdown","metadata":{"id":"pJdeguBZe8h9"},"source":["## 5. Align All Sections to a Common Date Range\n","\n","Different sections may have slightly different start/end dates due to missing data. We clip all DataFrames to the longest common period so that we can compare fairly."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ec1UdlvVe8h9","executionInfo":{"status":"ok","timestamp":1772319776767,"user_tz":360,"elapsed":21,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"1317da1d-070f-499f-8dea-af53ec93468c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Common date range: 2025-06-25 to 2025-08-10\n"]}],"source":["common_start = max(df_sec.index.min() for df_sec in feature_dfs.values())\n","common_end   = min(df_sec.index.max() for df_sec in feature_dfs.values())\n","print(f\"Common date range: {common_start.date()} to {common_end.date()}\")\n","\n","for sec in feature_dfs:\n","    feature_dfs[sec] = feature_dfs[sec].loc[common_start:common_end]"]},{"cell_type":"markdown","metadata":{"id":"g75m2CSNe8h9"},"source":["## 6. Load and Test Deployed Models\n","\n","The saved models are stored in the `deployment_models/` folder. We loop over every `.joblib` file (excluding baseline models, which are handled separately), load the corresponding artifacts, and run a quick prediction on the last five available data points. This verifies that the model loads correctly and that the prediction pipeline works.\n","\n","For each model type we use the appropriate method:\n","- **XGBoost / Random Forest**: direct `.predict()` on the feature matrix.\n","- **SVM**: features are scaled with the saved scaler before prediction.\n","- **Prophet**: requires a DataFrame with a `ds` column containing the future dates.\n","- **SARIMA**: uses `.predict(n_periods=...)`.\n","- **LSTM**: rebuilds the network from the saved state dict and forecasts one step ahead using the last `lookback` days.\n","- **Baselines** (Naive, Seasonal Naive, MA(7)): we print the last 14 stored values (the baseline logic can be extended if needed)."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9-s6VVRe8h9","executionInfo":{"status":"ok","timestamp":1772319835441,"user_tz":360,"elapsed":85,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"b7f48614-8497-4a4d-d6f8-ae050eaba70e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4 model files.\n","\n","\n","--- Testing XGBoost for Locaton D ---\n","Predictions: [30.095644 28.456524 29.044254 29.65153  28.70296 ]\n","\n","--- Testing XGBoost for Locaton B ---\n","Predictions: [29.5882   30.7317   31.589533 32.723454 35.911526]\n","\n","--- Testing Random Forest for Locaton C ---\n","Predictions: [25.988775 26.48315  27.21354  25.9371   29.5486  ]\n","\n","--- Testing XGBoost for Locaton A ---\n","Predictions: [32.837654 32.955177 32.745777 32.64806  25.466908]\n"]}],"source":["MODEL_DIR = 'deployment_models'\n","\n","# Get all section model files (excluding baseline models, which have 'baseline' in their filename)\n","model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith('.joblib') and 'baseline' not in f]\n","print(f\"Found {len(model_files)} model files.\\n\")\n","\n","for mf in model_files:\n","    path = os.path.join(MODEL_DIR, mf)\n","    artifacts = joblib.load(path)\n","\n","    sec = artifacts['section']\n","    model_name = artifacts['model_name']\n","    print(f\"\\n--- Testing {model_name} for Locaton {sec} ---\")\n","\n","    # Get the corresponding feature DataFrame for this section\n","    df_sec = feature_dfs[sec]\n","    feature_cols = artifacts['feature_columns']\n","    # Take the last 5 rows as a sample test set\n","    X_sample = df_sec[feature_cols].iloc[-5:]\n","\n","    # Prediction depends on model type\n","    if model_name in ('XGBoost', 'Random Forest'):\n","        model = artifacts['model']\n","        preds = model.predict(X_sample)\n","        print(\"Predictions:\", preds)\n","\n","    elif model_name == 'SVM':\n","        model = artifacts['model']\n","        scaler = artifacts['scaler']\n","        X_scaled = scaler.transform(X_sample)\n","        preds = model.predict(X_scaled)\n","        print(\"Predictions:\", preds)\n","\n","    elif model_name == 'Prophet':\n","        model = artifacts['model']\n","        # Prophet expects a DataFrame with column 'ds' (dates)\n","        future = pd.DataFrame({'ds': X_sample.index})\n","        forecast = model.predict(future)\n","        preds = forecast['yhat'].values\n","        print(\"Predictions:\", preds)\n","\n","    elif model_name == 'SARIMA':\n","        model = artifacts['model']\n","        # SARIMA's predict method needs the number of steps ahead\n","        preds = model.predict(n_periods=len(X_sample))\n","        print(\"Predictions:\", preds)\n","\n","    elif model_name == 'LSTM':\n","        # LSTM requires special handling: load state dict and rebuild model\n","        state_dict_path = os.path.join(MODEL_DIR, artifacts['state_dict_path'])\n","        lstm_model = LSTMModel()\n","        lstm_model.load_state_dict(torch.load(state_dict_path, map_location='cpu'))\n","        lstm_model.eval()\n","        lookback = artifacts.get('lookback', 7)\n","\n","        # Use the original target series to get the last 'lookback' values\n","        y_series = df_sec['y']\n","        if len(y_series) >= lookback:\n","            last_values = y_series.iloc[-lookback:].values.reshape(1, lookback, 1)\n","            inp = torch.tensor(last_values, dtype=torch.float32)\n","            with torch.no_grad():\n","                pred = lstm_model(inp).item()\n","            print(\"Prediction for next day:\", pred)\n","        else:\n","            print(\"Not enough history for LSTM test.\")\n","\n","    elif model_name in ('Naive', 'Seasonal Naive', 'MA(7)'):\n","        # Baseline models: we stored the last 14 actual values\n","        last_vals = artifacts['last_values']\n","        print(\"Baseline model - last 14 values:\", last_vals[-5:])  # show last 5 as a sample\n","        # (You could implement the actual baseline forecasting logic here)\n","\n","    else:\n","        print(f\"Unknown model type: {model_name}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}