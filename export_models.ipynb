{"cells":[{"cell_type":"markdown","metadata":{"id":"SjyxUoz-Zkg2"},"source":["# Export Best Models per Section\n","\n","This notebook trains each canteen section's best-performing model on the\n","**training set** (first 80 % of the data), evaluates it on the **test set**\n","(last 20 %), and serialises the artefacts to disk (`deployment_models/`).\n","Predictive-quality metrics and (for the LSTM) efficiency metrics are printed\n","and optionally saved with the model."]},{"cell_type":"markdown","metadata":{"id":"AAfMKaArZkg6"},"source":["---\n","## 1 -- Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU4y6UvGZkg8","executionInfo":{"status":"ok","timestamp":1772318284482,"user_tz":360,"elapsed":14034,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"411e41a9-7fbb-4147-f1d5-efc940595af3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pmdarima\n","  Downloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.5 kB)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.3)\n","Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.0.2)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\n","Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (0.14.6)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.5.0)\n","Requirement already satisfied: setuptools!=50.0.0,>=42 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (26.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.10.0+cpu)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.15.3-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14.5->pmdarima) (1.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.24.3)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n","Downloading pmdarima-2.1.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (689 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.3-py3-none-any.whl (31 kB)\n","Installing collected packages: lightning-utilities, torchmetrics, pmdarima\n","Successfully installed lightning-utilities-0.15.3 pmdarima-2.1.1 torchmetrics-1.8.2\n"]}],"source":["!pip install pmdarima torchmetrics"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3i4WA9IwZkg-","executionInfo":{"status":"ok","timestamp":1772318319443,"user_tz":360,"elapsed":34955,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["import os\n","import time\n","import warnings\n","from datetime import datetime\n","\n","import joblib\n","import numpy as np\n","import pandas as pd\n","\n","import xgboost as xgb\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data_utils\n","\n","from prophet import Prophet\n","import pmdarima as pm\n","\n","# optional -- use torchmetrics for more robust metrics\n","from torchmetrics import MeanAbsoluteError, MeanSquaredError, R2Score\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1LreMJUZkg-","executionInfo":{"status":"ok","timestamp":1772318345511,"user_tz":360,"elapsed":26051,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"d20036a9-6f70-4659-cc7f-49e481bad0a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Directory changed\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","try:\n","    os.chdir('/content/drive/MyDrive/UAB/FDS/campus-waste-intelligence')\n","    print('Directory changed')\n","except OSError:\n","    print(\"Error: Can't change the Current Working Directory\")"]},{"cell_type":"markdown","metadata":{"id":"V_nRhnsAZkg_"},"source":["---\n","## 2 -- Configuration & Constants"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0I8O1ENsZkg_","executionInfo":{"status":"ok","timestamp":1772318345986,"user_tz":360,"elapsed":472,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["DATA_PATH   = 'data/food_waste_cleaned.csv'\n","MODEL_DIR   = 'deployment_models'\n","\n","# Split ratio: first SPLIT_RATIO * 100 % of rows are training, the rest test\n","SPLIT_RATIO = 0.8\n","\n","LOOKBACK    = 7\n","LSTM_HIDDEN = 50\n","LSTM_LAYERS = 2\n","EPOCHS      = 50\n","BATCH_SIZE  = 16\n","LR          = 0.001\n","\n","os.makedirs(MODEL_DIR, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"W4d6Pb4lZkhA"},"source":["---\n","## 3 -- Load and Aggregate Data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BX6lknOZkhA","executionInfo":{"status":"ok","timestamp":1772318348872,"user_tz":360,"elapsed":2882,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"c9ca028c-c7d9-495a-f432-a5383ef411e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sections found: ['A', 'B', 'C', 'D']\n","Date range: 2025-06-11 00:00:00 to 2025-08-10 00:00:00\n"]}],"source":["df = pd.read_csv(DATA_PATH, parse_dates=['Date'])\n","\n","daily_section = (\n","    df.groupby(['Date', 'Canteen_Section'])['Waste_Weight_kg']\n","      .sum()\n","      .reset_index()\n","      .rename(columns={'Waste_Weight_kg': 'Total_Waste_kg'})\n",")\n","\n","daily_wide = (\n","    daily_section\n","    .pivot(index='Date', columns='Canteen_Section', values='Total_Waste_kg')\n","    .fillna(0)\n","    .sort_index()\n","    .asfreq('D')\n","    .fillna(0)\n",")\n","\n","sections = daily_wide.columns.tolist()\n","print(f'Sections found: {sections}')\n","print(f'Date range: {daily_wide.index.min()} to {daily_wide.index.max()}')"]},{"cell_type":"markdown","metadata":{"id":"jtnTxgkUZkhA"},"source":["---\n","## 4 -- Feature Engineering"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VIwK2zN6ZkhA","executionInfo":{"status":"ok","timestamp":1772318348899,"user_tz":360,"elapsed":3,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def create_features_for_series(series: pd.Series) -> pd.DataFrame:\n","    \"\"\"Build lag, rolling-window, and calendar features for a single series.\"\"\"\n","    df_ml = pd.DataFrame(index=series.index)\n","    df_ml['y'] = series.values\n","\n","    # Calendar features\n","    df_ml['dayofweek'] = df_ml.index.dayofweek\n","    df_ml['day']       = df_ml.index.day\n","    df_ml['month']     = df_ml.index.month\n","    df_ml['quarter']   = df_ml.index.quarter\n","    df_ml['weekend']   = (df_ml.index.dayofweek >= 5).astype(int)\n","\n","    # Lag features\n","    for lag in [1, 2, 3, 7, 14]:\n","        df_ml[f'lag_{lag}'] = df_ml['y'].shift(lag)\n","\n","    # Rolling-window features (shifted by 1 to avoid look-ahead)\n","    shifted = df_ml['y'].shift(1)\n","    df_ml['rolling_mean_7'] = shifted.rolling(7).mean()\n","    df_ml['rolling_std_7']  = shifted.rolling(7).std()\n","    df_ml['rolling_min_7']  = shifted.rolling(7).min()\n","    df_ml['rolling_max_7']  = shifted.rolling(7).max()\n","    df_ml['ewm_mean_7']    = shifted.ewm(span=7).mean()\n","\n","    df_ml.dropna(inplace=True)\n","    return df_ml"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cdv2tAQZkhB","executionInfo":{"status":"ok","timestamp":1772318348971,"user_tz":360,"elapsed":53,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"e65f8903-3dc9-4dfa-ea22-edcd55b6e51e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Common date range: 2025-06-25 to 2025-08-10\n","Rows per section:  47\n"]}],"source":["feature_dfs: dict[str, pd.DataFrame] = {}\n","\n","for sec in sections:\n","    feature_dfs[sec] = create_features_for_series(daily_wide[sec])\n","\n","# Align all sections to the same date window\n","common_start = max(df_sec.index.min() for df_sec in feature_dfs.values())\n","common_end   = min(df_sec.index.max() for df_sec in feature_dfs.values())\n","\n","for sec in sections:\n","    feature_dfs[sec] = feature_dfs[sec].loc[common_start:common_end]\n","\n","print(f'Common date range: {common_start.date()} to {common_end.date()}')\n","print(f'Rows per section:  {len(feature_dfs[sections[0]])}')"]},{"cell_type":"markdown","metadata":{"id":"xGgAULbqZkhB"},"source":["---\n","## 5 -- Train / Test Split (percentage-based, sequential)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wYh4i7wZkhB","executionInfo":{"status":"ok","timestamp":1772318348992,"user_tz":360,"elapsed":19,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"e8724fb5-1801-4f9a-ae84-11d89d821e36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total rows: 47\n","Train rows: 37 (80%)\n","Test rows : 10 (20%)\n"]}],"source":["ref_index = feature_dfs[sections[0]].index\n","n_total   = len(ref_index)\n","n_train   = int(n_total * SPLIT_RATIO)\n","\n","train_indices = ref_index[:n_train]\n","test_indices  = ref_index[n_train:]\n","\n","train_mask = ref_index.isin(train_indices)\n","test_mask  = ref_index.isin(test_indices)\n","\n","print(f'Total rows: {n_total}')\n","print(f'Train rows: {n_train} ({SPLIT_RATIO:.0%})')\n","print(f'Test rows : {n_total - n_train} ({1 - SPLIT_RATIO:.0%})')"]},{"cell_type":"markdown","metadata":{"id":"L6GZX-gwZkhB"},"source":["---\n","## 6 -- Best Model per Section (hard-coded)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y19KbAiHZkhB","executionInfo":{"status":"ok","timestamp":1772318349040,"user_tz":360,"elapsed":46,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"4f74100f-64c9-40af-f662-a20a8596b408"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'A': 'XGBoost', 'B': 'XGBoost', 'C': 'Random Forest', 'D': 'XGBoost'}"]},"metadata":{},"execution_count":9}],"source":["best_models: dict[str, str] = {\n","    'A': 'XGBoost',\n","    'B': 'XGBoost',\n","    'C': 'Random Forest',\n","    'D': 'XGBoost',\n","}\n","\n","best_models"]},{"cell_type":"markdown","metadata":{"id":"hChCNmPZZkhB"},"source":["---\n","## 7 -- LSTM Architecture"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2-U8vsIeZkhC","executionInfo":{"status":"ok","timestamp":1772318349043,"user_tz":360,"elapsed":6,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    \"\"\"Simple stacked-LSTM regressor.\"\"\"\n","\n","    def __init__(\n","        self,\n","        input_size: int = 1,\n","        hidden_size: int = LSTM_HIDDEN,\n","        num_layers: int = LSTM_LAYERS,\n","        output_size: int = 1,\n","    ):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc   = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])\n","        return out.squeeze()"]},{"cell_type":"markdown","metadata":{"id":"BVZPnofBZkhC"},"source":["---\n","## 8 -- Sequence Helper"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vdFPjsPOZkhC","executionInfo":{"status":"ok","timestamp":1772318349071,"user_tz":360,"elapsed":25,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def create_sequences(\n","    data: np.ndarray, lookback: int = LOOKBACK\n",") -> tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Slide a window of *lookback* steps over *data* and return (X, y) arrays.\"\"\"\n","    xs, ys = [], []\n","    for i in range(lookback, len(data)):\n","        xs.append(data[i - lookback : i])\n","        ys.append(data[i])\n","    return np.array(xs), np.array(ys)"]},{"cell_type":"markdown","metadata":{"id":"CepnHCHHZkhC"},"source":["---\n","## 9 -- Metrics Helper"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8mS8U2TaZkhC","executionInfo":{"status":"ok","timestamp":1772318349073,"user_tz":360,"elapsed":6,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def compute_regression_metrics(\n","    y_true: np.ndarray, y_pred: np.ndarray\n",") -> dict[str, float]:\n","    \"\"\"Return RMSE, MAE, MAPE, and R-squared.\"\"\"\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    mae  = mean_absolute_error(y_true, y_pred)\n","\n","    # Avoid division by zero in MAPE\n","    mask = y_true != 0\n","    mape = (\n","        np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n","        if mask.sum() > 0\n","        else np.nan\n","    )\n","\n","    r2 = r2_score(y_true, y_pred)\n","\n","    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}"]},{"cell_type":"markdown","metadata":{"id":"n0vxxOMmZkhC"},"source":["---\n","## 10 -- Per-Model Training Helpers"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"dMaBLO6_ZkhC","executionInfo":{"status":"ok","timestamp":1772318349078,"user_tz":360,"elapsed":4,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_tree_model(\n","    model_name: str,\n","    X_train: pd.DataFrame,\n","    y_train: pd.Series,\n","    X_test: pd.DataFrame,\n","):\n","    \"\"\"Train an XGBoost or Random Forest model and return (model, test_pred).\"\"\"\n","    if model_name == 'XGBoost':\n","        model = xgb.XGBRegressor(\n","            n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42,\n","        )\n","    else:\n","        model = RandomForestRegressor(\n","            n_estimators=100, max_depth=10, random_state=42,\n","        )\n","    model.fit(X_train, y_train)\n","    test_pred = model.predict(X_test)\n","    return model, test_pred"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"PdUv668xZkhC","executionInfo":{"status":"ok","timestamp":1772318349082,"user_tz":360,"elapsed":2,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_svm(\n","    X_train: pd.DataFrame,\n","    y_train: pd.Series,\n","    X_test: pd.DataFrame,\n","):\n","    \"\"\"Train an SVR model with standard scaling; returns (model, test_pred, scaler).\"\"\"\n","    scaler = StandardScaler()\n","    X_scaled      = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    model = SVR(kernel='rbf', C=100, gamma='scale')\n","    model.fit(X_scaled, y_train)\n","\n","    test_pred = model.predict(X_test_scaled)\n","    return model, test_pred, scaler"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U1MmbMXgZkhD","executionInfo":{"status":"ok","timestamp":1772318349097,"user_tz":360,"elapsed":2,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_prophet(y_train: pd.Series, test_dates: pd.DatetimeIndex):\n","    \"\"\"Fit a Prophet model on training data and forecast for *test_dates*.\"\"\"\n","    df_prophet = pd.DataFrame({'ds': y_train.index, 'y': y_train.values})\n","\n","    model = Prophet(\n","        yearly_seasonality=False,\n","        weekly_seasonality=True,\n","        daily_seasonality=False,\n","    )\n","    model.fit(df_prophet)\n","\n","    # Predict on the exact test dates\n","    future    = pd.DataFrame({'ds': test_dates})\n","    forecast  = model.predict(future)\n","    test_pred = forecast['yhat'].values\n","    return model, test_pred"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"qWmkwq2_ZkhD","executionInfo":{"status":"ok","timestamp":1772318349101,"user_tz":360,"elapsed":3,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_sarima(y_train: pd.Series, test_dates: pd.DatetimeIndex):\n","    \"\"\"Fit auto-ARIMA with weekly seasonality and forecast for *test_dates*.\"\"\"\n","    model = pm.auto_arima(\n","        y_train,\n","        seasonal=True,\n","        m=7,\n","        trace=False,\n","        error_action='ignore',\n","        suppress_warnings=True,\n","        stepwise=True,\n","    )\n","\n","    n_test = len(test_dates)\n","    pred, _ = model.predict(n_periods=n_test, return_conf_int=True)\n","    test_pred = pred.values\n","    return model, test_pred"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"0FLWNeP8ZkhD","executionInfo":{"status":"ok","timestamp":1772318349128,"user_tz":360,"elapsed":24,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_lstm(\n","    sec: str,\n","    y_train: pd.Series,\n","    y_test: pd.Series,\n",") -> tuple:\n","    \"\"\"Train an LSTM model and return (model, test_pred, efficiency_dict).\n","\n","    Uses iterative (auto-regressive) prediction on the test set, seeded\n","    with the last *LOOKBACK* values of the training data.\n","    \"\"\"\n","    # -- Prepare training sequences -------------------------------------------\n","    X_seq, y_seq = create_sequences(y_train.values, lookback=LOOKBACK)\n","    X_tensor = torch.tensor(X_seq, dtype=torch.float32).unsqueeze(-1)\n","    y_tensor = torch.tensor(y_seq, dtype=torch.float32)\n","\n","    dataset = data_utils.TensorDataset(X_tensor, y_tensor)\n","    loader  = data_utils.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    # -- Build & train --------------------------------------------------------\n","    model     = LSTMModel()\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LR)\n","\n","    for _epoch in range(EPOCHS):\n","        model.train()\n","        for xb, yb in loader:\n","            optimizer.zero_grad()\n","            loss = criterion(model(xb), yb)\n","            loss.backward()\n","            optimizer.step()\n","\n","    # -- Iterative test-set prediction ----------------------------------------\n","    last_train  = y_train.values[-LOOKBACK:].reshape(1, LOOKBACK, 1)\n","    current_seq = torch.tensor(last_train, dtype=torch.float32)\n","\n","    test_pred: list[float] = []\n","    model.eval()\n","    with torch.no_grad():\n","        for _ in range(len(y_test)):\n","            pred = model(current_seq).item()\n","            test_pred.append(pred)\n","            new_val     = torch.tensor([[[pred]]], dtype=torch.float32)\n","            current_seq = torch.cat([current_seq[:, 1:, :], new_val], dim=1)\n","\n","    test_pred = np.array(test_pred)\n","\n","    # -- Efficiency metrics ---------------------------------------------------\n","    param_count = sum(p.numel() for p in model.parameters())\n","\n","    state_dict_path = f'{MODEL_DIR}/section_{sec}_lstm.pth'\n","    torch.save(model.state_dict(), state_dict_path)\n","    file_size_kb = os.path.getsize(state_dict_path) / 1024\n","\n","    # Average latency over 100 forward passes\n","    sample_input = torch.randn(1, LOOKBACK, 1)\n","    model.eval()\n","    t0 = time.perf_counter()\n","    for _ in range(100):\n","        _ = model(sample_input)\n","    latency_ms = (time.perf_counter() - t0) / 100 * 1000\n","\n","    efficiency = {\n","        'param_count': param_count,\n","        'model_size_kb': file_size_kb,\n","        'inference_latency_ms': latency_ms,\n","        'state_dict_path': f'section_{sec}_lstm.pth',\n","    }\n","    print(\n","        f'  LSTM efficiency: params={param_count}, '\n","        f'size={file_size_kb:.1f} KB, latency={latency_ms:.3f} ms'\n","    )\n","\n","    return model, test_pred, efficiency"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_5JI-S9_ZkhE","executionInfo":{"status":"ok","timestamp":1772318349132,"user_tz":360,"elapsed":2,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def _train_baseline(\n","    model_name: str,\n","    y_train: pd.Series,\n","    test_dates: pd.DatetimeIndex,\n","):\n","    \"\"\"Return a constant-prediction baseline and a lightweight 'model' dict.\"\"\"\n","    n_test = len(test_dates)\n","\n","    if model_name == 'Naive':\n","        value = y_train.iloc[-1]\n","    elif model_name == 'Seasonal Naive':\n","        value = y_train.iloc[-7] if len(y_train) >= 7 else y_train.iloc[0]\n","    elif model_name == 'MA(7)':\n","        value = y_train.iloc[-7:].mean() if len(y_train) >= 7 else y_train.mean()\n","    else:\n","        value = 0.0\n","\n","    test_pred = np.full(n_test, value)\n","\n","    # Lightweight model artefact for deployment\n","    model = {\n","        'last_values': y_train[-14:].tolist(),\n","        'last_dates': y_train.index[-14:].strftime('%Y-%m-%d').tolist(),\n","    }\n","    return model, test_pred"]},{"cell_type":"markdown","metadata":{"id":"IZ4eSXNOZkhE"},"source":["---\n","## 11 -- Train, Evaluate & Export Dispatcher"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"6541ReIqZkhE","executionInfo":{"status":"ok","timestamp":1772318349135,"user_tz":360,"elapsed":5,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}}},"outputs":[],"source":["def train_eval_export_section(sec: str, model_name: str) -> dict:\n","    \"\"\"Train *model_name* on the train set, evaluate on the test set,\n","    serialise artefacts to *MODEL_DIR*, and return a dict of test metrics.\"\"\"\n","    print(f\"\\n{'-' * 60}\")\n","    print(f'Training {model_name} for section {sec}')\n","\n","    df_ml = feature_dfs[sec]\n","    X = df_ml.drop('y', axis=1)\n","    y = df_ml['y']\n","\n","    X_train, y_train = X[train_mask], y[train_mask]\n","    X_test,  y_test  = X[test_mask],  y[test_mask]\n","\n","    feature_columns = X.columns.tolist()\n","\n","    artifacts: dict = {\n","        'section': sec,\n","        'model_name': model_name,\n","        'feature_columns': feature_columns,\n","        'lookback': LOOKBACK,\n","        'train_date_range': [\n","            train_indices.min().isoformat(),\n","            train_indices.max().isoformat(),\n","        ],\n","        'test_date_range': [\n","            test_indices.min().isoformat(),\n","            test_indices.max().isoformat(),\n","        ],\n","    }\n","\n","    # ---- Dispatch -----------------------------------------------------------\n","    if model_name in ('XGBoost', 'Random Forest'):\n","        model, test_pred = _train_tree_model(model_name, X_train, y_train, X_test)\n","\n","    elif model_name == 'SVM':\n","        model, test_pred, scaler = _train_svm(X_train, y_train, X_test)\n","        artifacts['scaler'] = scaler\n","\n","    elif model_name == 'Prophet':\n","        model, test_pred = _train_prophet(y_train, test_indices)\n","\n","    elif model_name == 'SARIMA':\n","        model, test_pred = _train_sarima(y_train, test_indices)\n","\n","    elif model_name == 'LSTM':\n","        model, test_pred, efficiency = _train_lstm(sec, y_train, y_test)\n","        artifacts.update(efficiency)\n","\n","    elif model_name in ('Naive', 'Seasonal Naive', 'MA(7)'):\n","        model, test_pred = _train_baseline(model_name, y_train, test_indices)\n","\n","    else:\n","        print(f\"  Unsupported model '{model_name}' for section {sec}\")\n","        return {}\n","\n","    # ---- Metrics & save -----------------------------------------------------\n","    metrics = compute_regression_metrics(y_test.values, test_pred)\n","    print(\n","        f\"  Test metrics: RMSE={metrics['RMSE']:.3f}, \"\n","        f\"MAE={metrics['MAE']:.3f}, \"\n","        f\"MAPE={metrics['MAPE']:.2f}%, \"\n","        f\"R2={metrics['R2']:.3f}\"\n","    )\n","\n","    artifacts['test_metrics'] = metrics\n","    artifacts['model'] = model\n","\n","    save_path = f'{MODEL_DIR}/section_{sec}.joblib'\n","    joblib.dump(artifacts, save_path)\n","    print(f'  Saved -> {save_path}')\n","\n","    return metrics"]},{"cell_type":"markdown","metadata":{"id":"ZkW3S63bZkhF"},"source":["---\n","## 12 -- Run Export Loop and Collect Metrics"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePq5i6_5ZkhF","executionInfo":{"status":"ok","timestamp":1772318352746,"user_tz":360,"elapsed":3599,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"da5383db-961a-470a-c8e7-506442c8ce75"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","------------------------------------------------------------\n","Training XGBoost for section A\n","  Test metrics: RMSE=6.981, MAE=5.829, MAPE=23.49%, R2=-0.793\n","  Saved -> deployment_models/section_A.joblib\n","\n","------------------------------------------------------------\n","Training XGBoost for section B\n","  Test metrics: RMSE=6.195, MAE=5.422, MAPE=22.06%, R2=0.084\n","  Saved -> deployment_models/section_B.joblib\n","\n","------------------------------------------------------------\n","Training Random Forest for section C\n","  Test metrics: RMSE=4.259, MAE=3.724, MAPE=13.10%, R2=-0.591\n","  Saved -> deployment_models/section_C.joblib\n","\n","------------------------------------------------------------\n","Training XGBoost for section D\n","  Test metrics: RMSE=6.898, MAE=6.188, MAPE=26.33%, R2=-3.698\n","  Saved -> deployment_models/section_D.joblib\n"]}],"source":["all_metrics: list[dict] = []\n","\n","for sec, model_name in best_models.items():\n","    metrics = train_eval_export_section(sec, model_name)\n","    if metrics:\n","        all_metrics.append({'Section': sec, 'Model': model_name, **metrics})"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LP9dXorLZkhF","executionInfo":{"status":"ok","timestamp":1772318352801,"user_tz":360,"elapsed":51,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"e940babe-e543-4eb8-9574-d51447cbbf48"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","SUMMARY OF TEST METRICS\n","============================================================\n","Section         Model     RMSE      MAE      MAPE        R2\n","      A       XGBoost 6.981413 5.828658 23.493827 -0.793069\n","      B       XGBoost 6.195208 5.422199 22.059672  0.083807\n","      C Random Forest 4.258691 3.723980 13.096007 -0.590600\n","      D       XGBoost 6.897860 6.188219 26.326522 -3.698431\n","\n","Summary saved to deployment_models/test_metrics_summary.csv\n"]}],"source":["# Summary table\n","print('\\n' + '=' * 60)\n","print('SUMMARY OF TEST METRICS')\n","print('=' * 60)\n","\n","summary_df = pd.DataFrame(all_metrics)\n","print(summary_df.to_string(index=False))\n","\n","summary_path = f'{MODEL_DIR}/test_metrics_summary.csv'\n","summary_df.to_csv(summary_path, index=False)\n","print(f'\\nSummary saved to {summary_path}')"]},{"cell_type":"markdown","metadata":{"id":"1QX0j4Z9ZkhF"},"source":["---\n","## 13 -- Verify Saved Artefacts"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1aveGLAJZkhF","executionInfo":{"status":"ok","timestamp":1772318352838,"user_tz":360,"elapsed":36,"user":{"displayName":"Dennis Kibet","userId":"11744330112719392161"}},"outputId":"0ef0d25e-c016-4a2f-87c3-387600f6dccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files in 'deployment_models/' (5):\n","\n","  section_A.joblib                             168.1 KB\n","  section_B.joblib                             154.0 KB\n","  section_C.joblib                             359.8 KB\n","  section_D.joblib                             167.3 KB\n","  test_metrics_summary.csv                       0.4 KB\n"]}],"source":["saved_files = sorted(os.listdir(MODEL_DIR))\n","print(f\"Files in '{MODEL_DIR}/' ({len(saved_files)}):\\n\")\n","for f in saved_files:\n","    size_kb = os.path.getsize(os.path.join(MODEL_DIR, f)) / 1024\n","    print(f'  {f:40s}  {size_kb:>8.1f} KB')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}